# API Семантического Поиска

Этот проект представляет собой API для умного поиска по PDF документам. Вы загружаете файлы, а система позволяет искать информацию внутри них, используя естественный язык (семантический поиск).

## Основные возможности API

### 1. Загрузка документа (`POST /api/v1/documents/upload`)

Загружает PDF файл в систему для обработки.

*   **Параметры**: Файл (`file`) обязателен. Можно настроить размер кусочков текста (`chunk_size`) и их перекрытие (`chunk_overlap`).
*   **Что происходит**: Файл считывается, текст разбивается на части и индексируется для будущего поиска.

**Пример ответа**:
```json
{
  "filename": "document.pdf",
  "total_pages": 10,
  "total_chunks": 25,
  "chunks": [...]
}
```

### 2. Поиск (`POST /api/v1/documents/search`)

Ищет наиболее подходящие фрагменты текста по всем загруженным документам.

*   **Тело запроса**:
    ```json
    {
      "query": "Ваш поисковый запрос здесь",
      "top_k": 5
    }
    ```
*   `query`: Текст запроса.
*   `top_k`: Сколько результатов вернуть (по умолчанию 5).

**Пример ответа**:
Возвращает список найденных фрагментов с указанием файла, страницы и степени похожесть (`score`).

---

## Запуск и использование (How to Run)

Проект можно запустить как в Docker, так и локально. Для удобства мы подготовили `Makefile`.

### Быстрый старт (Docker Compose)
Самый простой способ поднять всё окружение (API + База + Ollama + Milvus):

```bash
make up
```
Эта команда скачает образы, запустит контейнеры и автоматически загрузит нужную модель в Ollama.

Остановить и очистить:
```bash
make down
```

### Локальная разработка
Если вы хотите запускать код локально (без докера для самого приложения), вам пригодится менеджер пакетов `uv`.

1.  **Установка зависимостей**:
    ```bash
    make install
    ```
    (или `uv sync` вручную)

2.  **Запуск сервера**:
    ```bash
    make run
    ```
    Сервер будет доступен по адресу `http://localhost:8000`. Документация Swagger UI: `http://localhost:8000/docs`.

3.  **Запуск тестов**:
    ```bash
    make test
    ```

4.  **Проверка качества кода (Линтеры)**:
    ```bash
    make lint
    ```

---

## Как это работает под капотом: Детальный разбор индексации

Процесс обработки файла при загрузке (Endpoint `/upload`) состоит из нескольких этапов, каждый из которых выполняется отдельным компонентом:

### 1. Парсинг и извлечение текста (`PDFParser`)
Первым делом система получает байты вашего PDF файла.
*   **Компонент**: `src.infrastructure.pdf.pdf_parser.PDFParser`
*   **Действие**: Использует библиотеку `PyMuPDF` (fitz) для чтения файла. Проходится по каждой странице документа и вытаскивает оттуда "чистый" текст.
*   **Результат**: Список текстов, привязанных к номерам страниц (например: "Страница 1: Текст...", "Страница 2: Текст...").

### 2. Разбиение на чанки (`TextChunker`)
Текст страницы может быть слишком большим для нейросети, поэтому его нужно нарезать на кусочки (чанки).
*   **Компонент**: `src.infrastructure.pdf.text_chunker.TextChunker`
*   **Действие**: Берет текст страниц и делит его на блоки заданного размера (параметр `chunk_size`, по умолчанию 1000 символов). При нарезке делается "нахлест" (`chunk_overlap`, по умолчанию 200 символов), чтобы смысл не терялся на границах кусков.
*   **Результат**: Набор объектов `TextChunk`, где каждый чанк знает, с какой он страницы и какой у него текст.

### 3. Генерация эмбеддингов (`OllamaService`)
Чтобы компьютер "понял" смысл текста, он превращает слова в цифры.
*   **Компонент**: `src.infrastructure.embeddings.ollama_service.OllamaService`
*   **Действие**: Отправляет тексты чанков в нейросеть (Ollama), запущенную локально или на сервере. Нейросеть возвращает для каждого куска текста длинный список чисел (вектор), который математически описывает смысл текста.
*   **Результат**: Список векторов (эмбеддингов). Если размерность модели 768, вы получите список из 768 чисел для каждого чанка.

### 4. Сохранение данных (Transaction Manager & Milvus)
Данные сохраняются в двух местах:
1.  **PostgreSQL** (`SQLAlchemyTransactionManager`): Здесь хранятся метаданные документа (название файла, размер, кто загрузил, когда).
2.  **Milvus** (`MilvusService`): Это специализированная векторная база данных. Сюда записываются сами вектора (эмбеддинги) вместе с текстом чанка и ссылками на файл/страницу.

---

### Поиск (Search)
Поиск работает зеркально процессу индексации:
1.  Ваш текстовый запрос тоже превращается в вектор через `OllamaService`.
2.  `MilvusService` сравнивает этот вектор запроса со всеми векторами в базе.
3.  Находятся те вектора, которые "ближе" всего математически (по косинусному сходству) к вектору запроса. Это и есть самые похожие по смыслу куски текста.

---

## Структура Проекта (Слои)

Проект построен по принципам чистой архитектуры и разделен на слои:

*   **`Presentation`** (`src/presentation`): Слой взаимодействия с внешним миром. Здесь находятся контроллеры API (FastAPI), которые принимают HTTP запросы и возвращают ответы.
*   **`Application`** (`src/application`): Слой бизнес-логики. Здесь живут Use Cases (сценарии использования), которые управляют процессом (например, "Загрузить документ", "Найти документ") и координируют работу других компонентов.
*   **`Domain`** (`src/domain`): Слой предметной области. Содержит основные сущности и бизнес-правила, независимые от внешних инструментов.
*   **`Infrastructure`** (`src/infrastructure`): Слой инфраструктуры. Реализация работы с базой данных (Postgres, Milvus), внешними API (Ollama) и файловой системой. Все технические детали скрыты здесь.
